{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the selected tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.7)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open '/tmp/kernel-v2-263358duXCZ4v2Xezz.json'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def get_global_top_k_indices(data, k):\n",
    "\n",
    "    flattened = [(value, idx) for idx, value in enumerate(data)]\n",
    "    \n",
    "    top_k = sorted(flattened, key=lambda x: x[0], reverse=True)[:k] ##loss\n",
    "    \n",
    "    top_k_indices = [item[1] for item in top_k]  #item[2]+1 fix the first label biased to match the position\n",
    "    return top_k_indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ref_model_name_or_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "base_model_name_or_path = \"meta-llama/Llama-3.2-3B\"\n",
    "subset_size = 1\n",
    "data_prop=1\n",
    "\n",
    "ref_model_name = os.path.basename(ref_model_name_or_path)\n",
    "\n",
    "\n",
    "for idx in range(subset_size):\n",
    "    \n",
    "    ###train data\n",
    "    dataset_name_tag = f\"alpaca_52k-active-split_{idx}\"\n",
    "\n",
    "    if idx == 0:\n",
    "        cur_train_model_name = os.path.basename(base_model_name_or_path)\n",
    "    else:\n",
    "        cur_train_model_name = f\"lora_merged_alpaca_52k-active-split-5k_{idx-1}\"\n",
    "    \n",
    "\n",
    "    losses_cur_train = torch.load(f\"results/loss/token_losses_{dataset_name_tag}_{cur_train_model_name}.pt\")\n",
    "    losses_ref = torch.load(f\"results/loss/token_losses_{dataset_name_tag}_{ref_model_name}.pt\")\n",
    "\n",
    "    input_cur_train = [value for sublist in losses_cur_train for value in sublist]\n",
    "    input_ref = [value for sublist in losses_ref for value in sublist]\n",
    "\n",
    "    ##the calculation different loss of two models\n",
    "    losses_diff = [loss1 - loss2 for loss1, loss2 in zip(input_cur_train, input_ref)]\n",
    "\n",
    "\n",
    "    all_token_count = sum(len(losses) for losses in losses_ref)\n",
    "    print(f\"#### all token counting: {all_token_count}\\n\")\n",
    "\n",
    "    print(f\"model pair: ({cur_train_model_name}, {ref_model_name}) -- dataset: {dataset_name_tag}\")\n",
    "    print(f\"Token proportion with positive token loss: {round(sum(1 for loss in losses_diff if loss > 0) / len(losses_diff) * 100, 2)}%\")\n",
    "    select_global_tokens_indices = get_global_top_k_indices(losses_diff, int(all_token_count * data_prop))\n",
    "\n",
    "\n",
    "    plt.scatter(input_ref, input_cur_train, c='blue', alpha=0.3)\n",
    "\n",
    "    selected_train = [input_cur_train[i] for i in select_global_tokens_indices]\n",
    "    selected_ref = [input_ref[i] for i in select_global_tokens_indices]\n",
    "    plt.scatter(selected_ref, selected_train, c='red', label=\"Top Selected Tokens\", alpha=0.7)\n",
    "\n",
    "\n",
    "    # 添加标题和标签\n",
    "    plt.title(f\"Loss Comparison: {cur_train_model_name} vs {ref_model_name}\")\n",
    "    plt.xlabel(f\"{cur_train_model_name} Losses\")\n",
    "    plt.ylabel(f\"{ref_model_name} Losses\")\n",
    "    \n",
    "    min_val = min(min(input_cur_train), min(input_ref))\n",
    "    max_val = max(max(input_cur_train), max(input_ref))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='y = x')\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "    \n",
    "    # print(f\"Similarity ratio: {similarity_ratio:.2%}\")\n",
    "    # print(f\"Union ratio: {union_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.7)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open '/tmp/kernel-v2-263358duXCZ4v2Xezz.json'"
     ]
    }
   ],
   "source": [
    "losses_diff[select_global_tokens_indices[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.7)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open '/tmp/kernel-v2-263358duXCZ4v2Xezz.json'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def get_global_top_k_indices(data, k):\n",
    "    flattened = [(value, idx) for idx, value in enumerate(data)]\n",
    "    top_k = sorted(flattened, key=lambda x: x[0], reverse=True)[:k]  ##loss\n",
    "    top_k_indices = [item[1] for item in top_k]\n",
    "    return top_k_indices\n",
    "\n",
    "\n",
    "def get_half_positive_indices(data):\n",
    "    selected_flattened = [(value, idx) for idx, value in enumerate(data) if value > 0]\n",
    "    top_half_positive = sorted(selected_flattened, key=lambda x: x[0], reverse=True)[:int(len(selected_flattened)/2)] ##loss\n",
    "\n",
    "    top_half_positive_indices = [item[1] for item in top_half_positive]\n",
    "    return top_half_positive_indices\n",
    "\n",
    "def get_curve_positive_indices(losses_pre, losses_cur):\n",
    "    \n",
    "    alpha = 2\n",
    "    beta = 0.07\n",
    "    curve_positive_indices=[]\n",
    "    \n",
    "    for idx, (sample_losses_pre, sample_losses_cur) in enumerate(zip(losses_pre, losses_cur)):\n",
    "            if sample_losses_pre > alpha * sample_losses_cur + beta and sample_losses_cur <5: #linear split\n",
    "                curve_positive_indices.append(idx)\n",
    "\n",
    "    return curve_positive_indices\n",
    "\n",
    "# Data and training parameters\n",
    "###################################################\n",
    "loss_path=\"results/loss/\"\n",
    "ref_model_name_or_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "base_model_name_or_path = \"meta-llama/Llama-3.2-3B\"\n",
    "base_model_name = \"\"\n",
    "# dataset_name = \"alpaca_52k-active-split\"\n",
    "# dataset_name=\"filtered-cured-50k-active-split-global-curve-positive\"\n",
    "\n",
    "\n",
    "dataset_name=\"filtered-cured-50k-active-split-global-curve-positive-new\"\n",
    "# dataset_name=\"random_subset_50k-active-split-global-curve-positive-new\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global-curve-positive-new\"\n",
    "# dataset_name=\"random_subset_50k-iter-split-global-curve-positive-new\"\n",
    "\n",
    "subset_size = 5 # 增加子集数量以绘制多个子图\n",
    "data_prop = 0.6\n",
    "\n",
    "ref_model_name = os.path.basename(ref_model_name_or_path)\n",
    "\n",
    "# 创建一个大的图形框架\n",
    "# fig, axes = plt.subplots(1, subset_size, figsize=(5 * subset_size, 4))\n",
    "\n",
    "fig, axes = plt.subplots(subset_size, 1, figsize=( 5, 4 * subset_size))\n",
    "\n",
    "\n",
    "for idx in range(subset_size):\n",
    "    dataset_name_tag = f\"{dataset_name}_{idx}\"\n",
    "\n",
    "    if idx == 0:\n",
    "        cur_train_model_name = os.path.basename(base_model_name_or_path)\n",
    "        cur_train_model_tag = os.path.basename(base_model_name_or_path)\n",
    "    else:\n",
    "        cur_train_model_name = f\"lora_merged_{dataset_name}_{idx-1}\"\n",
    "        cur_train_model_tag = f\"{idx}th-iteration training model\"\n",
    "        \n",
    "    # losses_cur_train = torch.load(f\"results/loss/token_losses_{dataset_name_tag}_{cur_train_model_name}.pt\")\n",
    "    # losses_ref = torch.load(f\"results/loss/token_losses_{dataset_name_tag}_{ref_model_name}.pt\")\n",
    "    \n",
    "    if \"Llama-3.2-3B\" in cur_train_model_name: ## load from existing model\n",
    "        if \"filtered-cured-50k\" in dataset_name_tag:\n",
    "            base_loss_path = loss_path + f\"token_losses_filtered-cured-50k_all_{cur_train_model_name}.pt\" \n",
    "        elif \"random_subset_50k\" in dataset_name_tag:\n",
    "            base_loss_path = loss_path + f\"token_losses_random_subset_50k_all_{cur_train_model_name}.pt\"    \n",
    "        else:\n",
    "            print(\"unknow dataset, please check whether generate the loss for base model.\")\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        print(f\"load the first round base model from existing file: {base_loss_path}\")\n",
    "        all_losses = torch.load(base_loss_path)\n",
    "        subset_examples = int(len(all_losses) / subset_size)\n",
    "        losses_cur_train = all_losses[:subset_examples]\n",
    "        \n",
    "    else:\n",
    "        losses_cur_train = torch.load(loss_path + f\"token_losses_{dataset_name_tag}_{cur_train_model_name}.pt\")\n",
    "        \n",
    "\n",
    "        ############### reference model loss #############\n",
    "    if \"filtered-cured-50k\" in dataset_name_tag and ref_model_name == \"Llama-3.1-8B-Instruct\":\n",
    "        reference_loss_path = loss_path + f\"token_losses_filtered-cured-50k_all_{ref_model_name}.pt\"\n",
    "    elif \"random_subset_50k\" in dataset_name_tag and ref_model_name == \"Llama-3.1-8B-Instruct\":\n",
    "        reference_loss_path = loss_path + f\"token_losses_random_subset_50k_all_{ref_model_name}.pt\"\n",
    "    else:\n",
    "        reference_loss_path = None\n",
    "        \n",
    "    ### reuse the existing reference loss\n",
    "    if  reference_loss_path and os.path.exists(reference_loss_path):\n",
    "        print(f\"load the reference losses from existing file: {reference_loss_path}\")\n",
    "        all_losses = torch.load(reference_loss_path)\n",
    "        subset_examples = int(len(all_losses) / subset_size)\n",
    "        losses_ref = all_losses[idx*subset_examples:(idx+1)*subset_examples]\n",
    "    else:\n",
    "        losses_ref = torch.load(f\"results/loss/token_losses_{dataset_name_tag}_{ref_model_name}.pt\")\n",
    "\n",
    "    input_cur_train = [value for sublist in losses_cur_train for value in sublist]\n",
    "    input_ref = [value for sublist in losses_ref for value in sublist]\n",
    "\n",
    "    # 计算两个模型的损失差异\n",
    "    losses_diff = [loss1 - loss2 for loss1, loss2 in zip(input_cur_train, input_ref)]\n",
    "\n",
    "    all_token_count = sum(len(losses) for losses in losses_ref)\n",
    "    print(f\"#### all token counting: {all_token_count}\\n\")\n",
    "\n",
    "    print(f\"Dataset: {dataset_name_tag} -- Token proportion with positive loss diff : {round(sum(1 for loss in losses_diff if loss > 0) / len(losses_diff) * 100, 2)}%\")\n",
    "\n",
    "    # select_global_tokens_indices = get_global_top_k_indices(losses_diff, int(all_token_count * data_prop))\n",
    "    # select_global_tokens_indices = get_half_positive_indices(losses_diff)\n",
    "    select_global_tokens_indices = get_curve_positive_indices(input_cur_train, input_ref)\n",
    "    print(f\"Dataset: {dataset_name_tag} -- selected Token proportion with positive loss diff: {round(len(select_global_tokens_indices) / len(losses_diff) * 100, 2)}%\")\n",
    "\n",
    "    # 选择合适的子图\n",
    "    ax = axes[idx]  # 选择对应的子图轴\n",
    "\n",
    "    # 绘制散点图\n",
    "    ax.scatter(input_ref, input_cur_train, c='lightblue', s=1, alpha=0.5, label='Orginal Tokens')\n",
    "\n",
    "    selected_train = [input_cur_train[i] for i in select_global_tokens_indices]\n",
    "    selected_ref = [input_ref[i] for i in select_global_tokens_indices]\n",
    "    ax.scatter(selected_ref, selected_train, c='salmon', s=1, label=\"Selected Tokens\", alpha=0.7)\n",
    "\n",
    "    # 添加标题和标签\n",
    "    ax.set_title(f\"{dataset_name_tag}\")\n",
    "    ax.set_xlabel(f\"{ref_model_name} Losses\")\n",
    "    ax.set_ylabel(f\"{cur_train_model_tag} Losses\")\n",
    "\n",
    "    # 绘制对角线 y = x\n",
    "    min_val = min(min(input_cur_train), min(input_ref))\n",
    "    max_val = max(max(input_cur_train), max(input_ref))\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], color='black', linestyle='--', label='y = x')\n",
    "\n",
    "    # x_vals = np.linspace(min_val, max_val, 500)\n",
    "    # y_vals = 1.2 * x_vals + 3\n",
    "    # ax.plot(x_vals, y_vals, color='black', linestyle='-', label='y = 1.2x +3')\n",
    "    ax.set_xscale('log')  # 如果你想要对 x 轴应用对数尺度\n",
    "    ax.set_yscale('log')  # 如果你想要对 y 轴应用对数尺度\n",
    "    \n",
    "    ax.set_xlim(0, 30)\n",
    "    ax.set_ylim(0, 30)\n",
    "    # 显示图例\n",
    "    ax.legend(fontsize=12, markerscale=5)\n",
    "\n",
    "# 调整图形布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示所有子图\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.7)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open '/tmp/kernel-v2-263358duXCZ4v2Xezz.json'"
     ]
    }
   ],
   "source": [
    "def get_curve_positive_indices(losses_pre, losses_cur):\n",
    "    \n",
    "    alpha = 2\n",
    "    beta = 0.07\n",
    "    curve_positive_indices=[]\n",
    "    \n",
    "    for idx, (sample_losses_pre, sample_losses_cur) in enumerate(zip(losses_pre, losses_cur)):\n",
    "            if sample_losses_pre > alpha * sample_losses_cur + beta and sample_losses_cur < 5: #linear split\n",
    "                curve_positive_indices.append(idx)\n",
    "\n",
    "    return curve_positive_indices\n",
    "\n",
    "select_global_tokens_indices = get_curve_positive_indices(input_cur_train, input_ref)\n",
    "\n",
    "len(select_global_tokens_indices) /len(losses_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.7)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open '/tmp/kernel-v2-263358duXCZ4v2Xezz.json'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.7)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open '/tmp/kernel-v2-263358duXCZ4v2Xezz.json'"
     ]
    }
   ],
   "source": [
    "half_indices = get_half_positive_indices(losses_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.7)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open '/tmp/kernel-v2-263358duXCZ4v2Xezz.json'"
     ]
    }
   ],
   "source": [
    "losses_diff[half_indices[-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
