## LLM Token Selection
- Reference: [Not All Tokens Are What You Need for Pretraining](https://openreview.net/pdf?id=0NMzBwqaAJ), NeurIPS 2024 best paper runner up.

This repo is to analyze the token-level data selection for LLM instruction tunning.


## Data Preparation

One can check the `data_preprocess.ipynb`

## Code Running

One can use the `run_all.sh`.