{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results DataFrame (Reordered with Average, Percentage Format):\n",
      "\n",
      "                                                                                            truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-1           45.46   49.38   27.44  57.31      56.10          45.91  76.87     51.2\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-2           46.67   53.00   27.44  56.89      56.25          46.51  77.15     52.0\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-3           48.91   53.53   28.22  56.43      56.13          46.43  77.36     52.4\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-4           51.07   54.69   28.22  56.18      55.81          45.99  77.33     52.8\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-5           52.24   55.23   27.29  56.16      55.49          45.65  77.30     52.8\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-6           52.63   57.70   27.44  56.05      55.18          45.56  77.52     53.2\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-7           52.71   56.09   27.75  55.97      54.61          45.39  77.05     52.8\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-8           53.15   56.95   27.29  55.89      54.32          45.13  76.96     52.8\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-9           53.42   57.23   26.82  55.87      54.09          44.53  76.78     52.7\n",
      "\n",
      "################################################################################\n",
      "LaTeX Form:\n",
      "################################################################################\n",
      "\\begin{table}\n",
      "\\caption{模型评估结果}\n",
      "\\label{tab:results}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      " & truthfulqa_mc2 & tydiqa & logiqa & mmlu & hellaswag & arc_challenge & boolq & Average \\\\\n",
      "\\midrule\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-1 & 45.46 & 49.38 & 27.44 & 57.31 & 56.10 & 45.91 & 76.87 & 51.20 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-2 & 46.67 & 53.00 & 27.44 & 56.89 & 56.25 & 46.51 & 77.15 & 52.00 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-3 & 48.91 & 53.53 & 28.22 & 56.43 & 56.13 & 46.43 & 77.36 & 52.40 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-4 & 51.07 & 54.69 & 28.22 & 56.18 & 55.81 & 45.99 & 77.33 & 52.80 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-5 & 52.24 & 55.23 & 27.29 & 56.16 & 55.49 & 45.65 & 77.30 & 52.80 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-6 & 52.63 & 57.70 & 27.44 & 56.05 & 55.18 & 45.56 & 77.52 & 53.20 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-7 & 52.71 & 56.09 & 27.75 & 55.97 & 54.61 & 45.39 & 77.05 & 52.80 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-8 & 53.15 & 56.95 & 27.29 & 55.89 & 54.32 & 45.13 & 76.96 & 52.80 \\\\\n",
      "filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-9 & 53.42 & 57.23 & 26.82 & 55.87 & 54.09 & 44.53 & 76.78 & 52.70 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lm_eval.utils import make_table\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "############# base model #########\n",
    "base_model=\"meta-llama/Llama-3.2-3B\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "########### train data tag ###############\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_combine_active-split-data-prop-0.6-fixed-base-loss-using-warmup-label_llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-with-prompt\" \n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-with-prompt\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama8b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-mistral\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama3b-new\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "######### model-tags ##########\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.7_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-10k-warmup-llama3b\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_all\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.8_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-full-baseline\" \n",
    "# dataset_name=\"filtered-cured-50k-random-baseline\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama8b-global\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-mistral-global\" \n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.4_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.5_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.9_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama3b-global-ref-8binst\"\n",
    "# dataset_name=\"base\"\n",
    "\n",
    "# dataset_name=\"full-300k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b\"\n",
    "# model_tags=[f'{dataset_name}_0', f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3', f'{dataset_name}_4'] #\n",
    "# model_tags=[f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3', f'{dataset_name}_4', f'{dataset_name}_5', f'{dataset_name}_6', f'{dataset_name}_7', f'{dataset_name}_8', f'{dataset_name}_9'] #\n",
    "\n",
    "# model_tags=[f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3'] #\n",
    "model_tags=[f'{dataset_name}']\n",
    "# model_tags=[f'{dataset_name}_4']\n",
    "data_prop = 0.3\n",
    "\n",
    "# if \"0.3\" in dataset_name:\n",
    "#     data_prop = 0.3\n",
    "# elif \"0.4\" in dataset_name:\n",
    "#     data_prop = 0.4\n",
    "# elif \"0.5\" in dataset_name:\n",
    "#     data_prop = 0.5\n",
    "# elif \"0.6\" in dataset_name:\n",
    "#     data_prop = 0.6\n",
    "# elif \"0.7\" in dataset_name:\n",
    "#     data_prop = 0.7\n",
    "# elif \"0.8\" in dataset_name:\n",
    "#     data_prop = 0.8\n",
    "# elif \"0.9\" in dataset_name:\n",
    "#     data_prop = 0.9\n",
    "# else:\n",
    "#     data_prop=0.0\n",
    "\n",
    "\n",
    "TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "\n",
    "results_all = {}\n",
    "for model_tag in model_tags:\n",
    "    \n",
    "    data_path = f\"token_selection_results/{data_prop}/{model_tag}/\"\n",
    "    # temp = os.listdir(data_path)[-1]\n",
    "    \n",
    "    if model_tag != 'base':\n",
    "        exp_files = os.listdir(data_path)\n",
    "        # print(exp_files)\n",
    "        for file_name in exp_files:\n",
    "            if str(data_prop) in file_name and os.path.basename(base_model) in file_name: ## search the file based on data proportion\n",
    "                temp = file_name\n",
    "    else:\n",
    "        temp = os.listdir(data_path)[0]\n",
    "        # temp_file_path = [name for name in temp if os.path.isdir(os.path.join(data_path, name))]\n",
    "\n",
    "    data_path = os.path.join(data_path, temp)\n",
    "    json_files = os.listdir(data_path)\n",
    "\n",
    "    results = {}\n",
    "    for file in json_files:\n",
    "        with open(os.path.join(data_path, file), 'r') as f:\n",
    "            temp = json.load(f)\n",
    "            # print(\"#\"* 50 + \"\\n\")\n",
    "            for task in TASK_LISTS:\n",
    "                if task in temp['results'].keys():\n",
    "                    # print(temp['results'][task])\n",
    "                    \n",
    "                    if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                        metric = 'acc,none'\n",
    "                    elif task == 'gsm8k':\n",
    "                        metric = 'exact_match,strict-match'\n",
    "                    elif task == \"triviaqa\":\n",
    "                        metric = \"exact_match,remove_whitespace\"\n",
    "                    elif task == 'bbh':\n",
    "                        metric = 'exact_match,get-answer' \n",
    "                    results[task] = temp['results'][task][metric]\n",
    "    \n",
    "    ####### tydiqa file #########\n",
    "    if os.path.exists(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\"):\n",
    "        with open(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\", 'r') as f:\n",
    "            temp = json.load(f)\n",
    "            results['tydiqa'] = round(temp['average']['f1'] / 100, 4)\n",
    "    ###########################\n",
    "    \n",
    "    results_all[model_tag] = results\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"hellaswag\" ] #\n",
    "# TASK_LISTS=[\"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']\n",
    "\n",
    "# TASK_LISTS=['truthfulqa_mc2', \"tydiqa\", \"hellaswag\", \"arc_challenge\", \"openbookqa\", \"boolq\"] #\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "# TASK_LISTS=['mmlu', 'bbh',  'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "\n",
    "# TASK_LISTS=[\"sciq\", \"triviaqa\", \"piqa\", 'arc_easy', 'logiqa', 'winogrande']\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"hellaswag\", \"arc_challenge\", \"openbookqa\", 'boolq', 'sciq', \"triviaqa\", \"piqa\", 'arc_easy', 'logiqa',  'winogrande'] ##task\n",
    "\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"hellaswag\", \"arc_challenge\", \"openbookqa\", 'boolq', 'logiqa'] ##task\n",
    "\n",
    "TASK_LISTS=[\"truthfulqa_mc2\", \"tydiqa\", 'logiqa', 'mmlu',  \"hellaswag\", \"arc_challenge\", \"boolq\"]\n",
    "\n",
    "results_df = results_df[TASK_LISTS]\n",
    "results_df = results_df.map(lambda x: round(100*x, 2) if pd.notnull(x) else x)\n",
    "results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "results_df = results_df.reindex(model_tags)\n",
    "results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "print(results_df.to_string(line_width=1000))\n",
    "\n",
    "latex_table = results_df.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "\n",
    "# 打印 LaTeX 表格到控制台\n",
    "print(\"\\n\" +\"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80 )\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
